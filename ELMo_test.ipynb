{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELMo-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMW7Qa1xB+MM1ng1ElGZHul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hydradon/modelling-with-pythhon/blob/master/ELMo_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aFHLRfmydLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\n",
        "!pip3 install tensorflow_text==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOd905xvo40w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_6-ad_QpdvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "df874bbb-1b5c-4e0c-85ce-8ef3e5124984"
      },
      "source": [
        "# Import data\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/hydradon/modelling-with-pythhon/master/dataset/tweet_sentiments/train.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/hydradon/modelling-with-pythhon/master/dataset/tweet_sentiments/test.csv\")\n",
        "\n",
        "# sample view\n",
        "train.sample(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5458</th>\n",
              "      <td>5459</td>\n",
              "      <td>0</td>\n",
              "      <td>P I N K M O N D A Y. #monday #work #truefruits #evian #pink #fruits #pinkmonday #apple… https://www.instagram.com/p/BBzVaFzQaAT/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084</th>\n",
              "      <td>2085</td>\n",
              "      <td>1</td>\n",
              "      <td>@Vivo_India @UnboxTherapy Scamsters! Advertised a sale. Site went down 10 min's before the sale. Came back up &amp; all gone. http://www.isitdownrightnow.com reported site down for 10 mins. #vivofraud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3624</th>\n",
              "      <td>3625</td>\n",
              "      <td>0</td>\n",
              "      <td>iTunes sucks. So does Apple. I wish I could switch my fricken phone. #itunes #apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5002</th>\n",
              "      <td>5003</td>\n",
              "      <td>0</td>\n",
              "      <td>Thought this was #dope #tattoo #art #amazing #fffound #color #nice #body #life #iphone #filter http://instagr.am/p/L_cgq/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3513</th>\n",
              "      <td>3514</td>\n",
              "      <td>0</td>\n",
              "      <td>Happy Thanks Giving #phone #blackberry #samsung #apple #thanks #giving #share #family #muchl http://instagr.am/p/SXdIqjGspz/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>4069</td>\n",
              "      <td>0</td>\n",
              "      <td>#gadget #apple #ipad #mini #tablet #new #instatech #friday #2013 #january #ios gonna love this thing! http://instagr.am/p/UoMdCkD5WK/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>925</td>\n",
              "      <td>1</td>\n",
              "      <td>@blackeysbeats mine didn't even have the decency to split, it just concertina'd and died pic.twitter.com/W2WZ5S0k7Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7577</th>\n",
              "      <td>7578</td>\n",
              "      <td>0</td>\n",
              "      <td>my response to ios11 :) #apple #iphone #iphonex #losingfaith #ios11 #samsung #note8 #win #finallymadetheswitchpic.twitter.com/8OKfAOdEvS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6209</th>\n",
              "      <td>6210</td>\n",
              "      <td>0</td>\n",
              "      <td>My phone #samsung #blackberry #instagram #dailyphoto #instagrammers #new #now #doubletap… http://instagram.com/p/Zt_ZDhikEl/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5233</th>\n",
              "      <td>5234</td>\n",
              "      <td>1</td>\n",
              "      <td>Need to get a new phone *sighhh* my like millionth one :/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                                                                                                                                                                                    tweet\n",
              "5458  5459  ...                                                                         P I N K M O N D A Y. #monday #work #truefruits #evian #pink #fruits #pinkmonday #apple… https://www.instagram.com/p/BBzVaFzQaAT/\n",
              "2084  2085  ...  @Vivo_India @UnboxTherapy Scamsters! Advertised a sale. Site went down 10 min's before the sale. Came back up & all gone. http://www.isitdownrightnow.com reported site down for 10 mins. #vivofraud...\n",
              "3624  3625  ...                                                                                                                      iTunes sucks. So does Apple. I wish I could switch my fricken phone. #itunes #apple\n",
              "5002  5003  ...                                                                                Thought this was #dope #tattoo #art #amazing #fffound #color #nice #body #life #iphone #filter http://instagr.am/p/L_cgq/\n",
              "3513  3514  ...                                                                             Happy Thanks Giving #phone #blackberry #samsung #apple #thanks #giving #share #family #muchl http://instagr.am/p/SXdIqjGspz/\n",
              "4068  4069  ...                                                                    #gadget #apple #ipad #mini #tablet #new #instatech #friday #2013 #january #ios gonna love this thing! http://instagr.am/p/UoMdCkD5WK/\n",
              "924    925  ...                                                                                      @blackeysbeats mine didn't even have the decency to split, it just concertina'd and died pic.twitter.com/W2WZ5S0k7Z\n",
              "7577  7578  ...                                                                 my response to ios11 :) #apple #iphone #iphonex #losingfaith #ios11 #samsung #note8 #win #finallymadetheswitchpic.twitter.com/8OKfAOdEvS\n",
              "6209  6210  ...                                                                             My phone #samsung #blackberry #instagram #dailyphoto #instagrammers #new #now #doubletap… http://instagram.com/p/Zt_ZDhikEl/\n",
              "5233  5234  ...                                                                                                                                                Need to get a new phone *sighhh* my like millionth one :/\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEh-q_E9qEK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d007d441-8f6b-486a-89be-024807ad032d"
      },
      "source": [
        "# Check the distribution of labels\n",
        "train[\"label\"].value_counts(normalize = True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.744192\n",
              "1    0.255808\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IyI5DZxsb67",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z-6Roexq8lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Miscellanenous\n",
        "def clean_text(s: str) -> str:\n",
        "    s = re.sub(r'http\\S+', '', s) # Remove URL\n",
        "\n",
        "    punctuation = set('!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~')\n",
        "    s = ''.join([ch for ch in s if ch not in punctuation]) # Remove all punctuation\n",
        "\n",
        "    s = re.sub(r'\\d', ' ', s) # Remove number\n",
        "\n",
        "    s = \" \".join(s.split()) # Remove continuous whitespace\n",
        "\n",
        "    return s.lower()\n",
        "\n",
        "train[\"processed_tweet\"] = train[\"tweet\"].apply(clean_text)\n",
        "test[\"processed_tweet\"] = test[\"tweet\"].apply(clean_text)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLs8WoBpvAuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmatization\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# function to lemmatize text\n",
        "def lemmatization(texts):\n",
        "    output = []\n",
        "    for i in texts:\n",
        "        s = [token.lemma_ for token in nlp(i)]\n",
        "        output.append(' '.join(s))\n",
        "    return output\n",
        "\n",
        "train[\"processed_tweet\"] = lemmatization(train[\"processed_tweet\"])\n",
        "test[\"processed_tweet\"] = lemmatization(test[\"processed_tweet\"])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0UuO9Q1xt8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "f72e84cd-00b0-42e2-cf5e-148703064611"
      },
      "source": [
        "# View sample\n",
        "train.sample(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>2109</td>\n",
              "      <td>1</td>\n",
              "      <td>Thank you for the unnecessary headache, Apple. You and iCloud suck. #annoyed #wasteoftime Apple</td>\n",
              "      <td>thank -PRON- for the unnecessary headache , apple . -PRON- and icloud suck . annoyed wasteoftime apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>763</td>\n",
              "      <td>1</td>\n",
              "      <td>why does my Itunes think its acceptable to be a $&amp;@*# at this time #itsnot #apple #prick</td>\n",
              "      <td>why do -PRON- itune think -PRON- acceptable to be a at this time itsnot apple prick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1504</th>\n",
              "      <td>1505</td>\n",
              "      <td>0</td>\n",
              "      <td>#selfie pose,see yourself &amp; feel happy..it is important to be and yourself #Samsung #dubai pic.twitter.com/CnaUW3IqF4</td>\n",
              "      <td>selfie pose , see -PRON- feel happy .. -PRON- be important to be and -PRON- samsung dubai pic.twitter.comcnauw iqf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4257</th>\n",
              "      <td>4258</td>\n",
              "      <td>1</td>\n",
              "      <td>#fuckYou #apple I'll #buy another though #lightningcable #fail 6'ter isn't #cheap https://www.instagram.com/p/BCT4r-fCgJZ/</td>\n",
              "      <td>fuckyou apple -PRON- will buy another though lightningcable fail ' ter be not cheap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7784</th>\n",
              "      <td>7785</td>\n",
              "      <td>0</td>\n",
              "      <td>Crazy kid, always getting into something #instagram #iphone #4s #kittie #can #main$&amp;@*# #meow #b http://instagr.am/p/IwhVL9A5Zl/</td>\n",
              "      <td>crazy kid , always get into something instagram iphone s kittie can main meow b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6296</th>\n",
              "      <td>6297</td>\n",
              "      <td>0</td>\n",
              "      <td>RT: @alibakes Okay, I'm just going to reestablish how much I love my iPhone. Srsly. #iPhone #AT&amp;T #geek: R.. http://bit.ly/v4kfP</td>\n",
              "      <td>rt alibake okay , -PRON- be just go to reestablish how much i love -PRON- iphone . srsly . iphone att geek r ..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2408</th>\n",
              "      <td>2409</td>\n",
              "      <td>0</td>\n",
              "      <td>Just for fun #me #iPhone #new #instagram #white #instalove #instamood #instagood http://instagr.am/p/ORX6tIGUP5/</td>\n",
              "      <td>just for fun -PRON- iphone new instagram white instalove instamood instagood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4657</th>\n",
              "      <td>4658</td>\n",
              "      <td>1</td>\n",
              "      <td>Great I got to wait a whole hour to talk to someone about my iPhone !!!</td>\n",
              "      <td>great i get to wait a whole hour to talk to someone about -PRON- iphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3954</th>\n",
              "      <td>3955</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally ! My first very own iPhone \"iPhone X\". Imma proud momma ! #worthit #smartphone #iphone #iphonex #workhard #payoff #happiness #technology #future #gadget #cool #legit #fire #onfire #awesome...</td>\n",
              "      <td>finally -PRON- first very own iphone iphone x. imma proud momma worthit smartphone iphone iphonex workhard payoff happiness technology future gadget cool legit fire onfire awesome awesomeness ly p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>783</td>\n",
              "      <td>1</td>\n",
              "      <td>I would like to give a big old #fuckyou to #Apple due to the fact my ipad and iPhone will not connect</td>\n",
              "      <td>i would like to give a big old fuckyou to apple due to the fact -PRON- ipad and iphone will not connect</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                                                                                                                                                                          processed_tweet\n",
              "2108  2109  ...                                                                                                   thank -PRON- for the unnecessary headache , apple . -PRON- and icloud suck . annoyed wasteoftime apple\n",
              "762    763  ...                                                                                                                      why do -PRON- itune think -PRON- acceptable to be a at this time itsnot apple prick\n",
              "1504  1505  ...                                                                                       selfie pose , see -PRON- feel happy .. -PRON- be important to be and -PRON- samsung dubai pic.twitter.comcnauw iqf\n",
              "4257  4258  ...                                                                                                                      fuckyou apple -PRON- will buy another though lightningcable fail ' ter be not cheap\n",
              "7784  7785  ...                                                                                                                          crazy kid , always get into something instagram iphone s kittie can main meow b\n",
              "6296  6297  ...                                                                                          rt alibake okay , -PRON- be just go to reestablish how much i love -PRON- iphone . srsly . iphone att geek r ..\n",
              "2408  2409  ...                                                                                                                             just for fun -PRON- iphone new instagram white instalove instamood instagood\n",
              "4657  4658  ...                                                                                                                                  great i get to wait a whole hour to talk to someone about -PRON- iphone\n",
              "3954  3955  ...  finally -PRON- first very own iphone iphone x. imma proud momma worthit smartphone iphone iphonex workhard payoff happiness technology future gadget cool legit fire onfire awesome awesomeness ly p...\n",
              "782    783  ...                                                                                                  i would like to give a big old fuckyou to apple due to the fact -PRON- ipad and iphone will not connect\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIuQKmsFyjkd",
        "colab_type": "text"
      },
      "source": [
        "## Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJnYRQXDx1zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYQ4drdd1Ner",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "164c1065-cbcd-410c-bd05-8af2e12b8c2c"
      },
      "source": [
        "# just a random sentence\n",
        "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
        "\n",
        "# Extract ELMo features \n",
        "embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMYO0UTg4OXA",
        "colab_type": "text"
      },
      "source": [
        "### Building ELMo vectors for all Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Hc6-Bn4Nuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_elmo_vectors(x: pd.Series):\n",
        "    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(tf.tables_initializer())\n",
        "\n",
        "        # return average of ELMo features\n",
        "        return sess.run(tf.reduce_mean(embeddings,1))\n",
        "\n",
        "# Split data into batches\n",
        "train_batches = [train[i:i+100] for i in range(0, len(train), 100)]\n",
        "test_batches = [test[i:i+100] for i in range(0, len(test), 100)]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK3XJdJk2veP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get embedding\n",
        "elmo_train = [get_elmo_vectors(x['processed_tweet']) for x in train_batches]\n",
        "elmo_test = [get_elmo_vectors(x['processed_tweet']) for x in test_batches]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxkRCA9SFxe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concat all results from batch training\n",
        "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
        "elmo_test_new = np.concatenate(elmo_test, axis = 0)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD-qRLBXF7dm",
        "colab_type": "text"
      },
      "source": [
        "## Save models to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aKB3FhpFG9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d\")\n",
        "\n",
        "# save elmo_train_new\n",
        "pickle_out = open(\"elmo_train_{}.pickle\".format(timestr),\"wb\")\n",
        "pickle.dump(elmo_train_new, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# save elmo_test_new\n",
        "pickle_out = open(\"elmo_test_{}.pickle\".format(timestr),\"wb\")\n",
        "pickle.dump(elmo_test_new, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_1lUuVEF-_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load elmo_train_new\n",
        "pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
        "elmo_train_new = pickle.load(pickle_in)\n",
        "\n",
        "# load elmo_train_new\n",
        "pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
        "elmo_test_new = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB_GJPVHGFc6",
        "colab_type": "text"
      },
      "source": [
        "## Build model with ELMo embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt0kqqjeGI-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(elmo_train_new, \n",
        "                                                      train['label'],  \n",
        "                                                      random_state=42, \n",
        "                                                      test_size=0.2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMsvE9IpGWHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "bf46ee07-3080-494d-afe0-803c6b63913c"
      },
      "source": [
        "# Baseline score using LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_valid)\n",
        "print(\"F1 score of Logistic Regression model: {:2f}\".format(f1_score(y_pred, y_valid)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of Logistic Regression model: 0.762590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUON74sPHO7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction using ELMo\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}